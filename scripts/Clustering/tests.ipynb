{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e28ef7-a588-407d-b111-58d6af63d7fa",
   "metadata": {},
   "source": [
    "# Link taxpayers with clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ea2a0-d7fa-4542-a62a-aae0976c9d62",
   "metadata": {},
   "source": [
    "**Pre-treament or not ?**\n",
    "\n",
    "**Embedding models**\n",
    "* Word2Vec\n",
    "* all-mpnet-base-v2 (Abhishek et al. 2024) : https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "**Clustering methods**\n",
    "* k-means\n",
    "* DBSCAN\n",
    "* Agglomerative Hierarchical Clustering\n",
    "\n",
    "**References**\n",
    "* https://huggingface.co/blog/getting-started-with-embeddings\n",
    "* https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings?hl=en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b5088-79f6-455a-a449-a210fad5bee9",
   "metadata": {},
   "source": [
    "Code from https://www.sbert.net/examples/applications/semantic-search/README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2380aeb0-a9e7-47a5-a1be-18ef742254d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d2b7920-5677-449d-b013-7ab232e999d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/STual/DAN-cadastre/.venv_dan/lib/python3.10/site-packages']\n",
      "/home/STual/DAN-cadastre/scripts/Clustering\n",
      "/home/STual/DAN-cadastre/data\n",
      "/home/STual/DAN-cadastre/outputs/clustering\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(os.path.dirname(os.path.realpath(\"__file__\"))).resolve() # If not on GColab, BASE will be the directory of this notebook\n",
    "DATASETS = Path('/home/STual/DAN-cadastre/data').resolve()\n",
    "OUT_BASE = Path('/home/STual/DAN-cadastre/outputs/clustering').resolve()\n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15138579-1fcf-4dae-a627-69b9b021182e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bad6ac4-7a51-4b81-9357-6cedc38fd65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_all.json', '/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_0_100.json', '/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_400_500.json', '/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_100_200.json', '/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_200_300.json', '/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_500_600.json', '/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_300_400.json', '/home/STual/DAN-cadastre/data/Taxpayers/taxpayers_600_700.json']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "DATASET = DATASETS / \"Taxpayers\"\n",
    "files = glob.glob(str(DATASET) + '/*.json')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4756b6c-33ba-402b-967c-51aea78245c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Loop through the JSON files\n",
    "data = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "            data += json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eb1c25d-8b4c-42ca-b2db-ed51a78e5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('taxpayers_backup.json', 'w',encoding='utf-8') as f:\n",
    "#    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b430fc-b5b8-4c02-9652-fb369ea1b952",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "092ed7f4-d2f8-4aa4-8732-702a799a260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from str_normalization import remove_accents, normalize_text\n",
    "\n",
    "transcriptions_structured = []\n",
    "\n",
    "for d in data:\n",
    "    uuid = d[\"element_uuid\"]\n",
    "    counter = 1\n",
    "    try:\n",
    "        for taxpayer_json in d[\"entities_json\"][\"taxpayers\"]:\n",
    "            taxpayer_desc = []\n",
    "            if len(taxpayer_json['name']) > 0:\n",
    "                name = remove_accents(normalize_text(taxpayer_json['name']))\n",
    "                taxpayer_desc.append(name)\n",
    "            else:\n",
    "                taxpayer_desc.append('DONT TREAT NAME')\n",
    "            if len(taxpayer_json['firstnames']) > 0:\n",
    "                f_n = remove_accents(normalize_text(taxpayer_json['firstnames']))\n",
    "                f_n_s = f_n.split(' ')\n",
    "                #firstnames = sorted(f_n_s)\n",
    "                firstnames_ = \" \".join(f_n_s)\n",
    "                taxpayer_desc.append(firstnames_)\n",
    "            else:\n",
    "                taxpayer_desc.append('')\n",
    "            lst = [uuid,counter] + taxpayer_desc\n",
    "            transcriptions_structured.append(lst)\n",
    "            counter += 1\n",
    "    except:\n",
    "        print(taxpayer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f3e3989-b796-4c9e-b18f-d822a7dbec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ = [e[2] for e in transcriptions_structured]\n",
    "firstnames_ = [e[3] for e in transcriptions_structured]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138c117-82aa-438d-a78e-01f0ad8a3168",
   "metadata": {},
   "source": [
    "## 2. Compute similarities for each property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5300d84-1b60-4b52-a0b2-1cf05ed3d8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2844"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38a3933e-e0c4-4177-9a4a-c6038645d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time is equal to 0:01:07.895302\n"
     ]
    }
   ],
   "source": [
    "from embedding_similarity import compute_similarity_matrix\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "start = time.time()\n",
    "name_sim = compute_similarity_matrix(name_,0.85,top_k='ALL') #Pairs with a cosine similarity lower than 0.85 are not considered\n",
    "end = time.time()\n",
    "runtime = end-start\n",
    "print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "795ad9e0-8ef6-4d60-8507-8f638a2f2e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time is equal to 0:01:09.531571\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "firstnames_sim = compute_similarity_matrix(firstnames_,0.70,top_k='ALL') #Pairs with a cosine similarity lower than 0.70 are not considered\n",
    "end = time.time()\n",
    "runtime = end-start\n",
    "print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d349d-c0ad-4499-be86-97c4157d12b7",
   "metadata": {},
   "source": [
    "## 3. Intersection of similar pairs according several properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "920fe6c1-79a6-4061-9f09-af4d63a8e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding_similarity import find_common_similarities\n",
    "\n",
    "assert len(name_sim) == len(firstnames_sim)\n",
    "test = find_common_similarities(name_sim, firstnames_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dddfdd23-e6eb-4f23-bb4b-6f265ae47efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding_similarity import export_groups\n",
    "\n",
    "groups = export_groups(test)\n",
    "\n",
    "clusters = []\n",
    "for i in range(len(groups)):\n",
    "    #print(f\"\\n################# {i} #################\")\n",
    "    #print(groups[i])\n",
    "    c = []\n",
    "    for elem in groups[i]:\n",
    "        #print(transcriptions_structured[elem])\n",
    "        c.append(transcriptions_structured[elem])\n",
    "    clusters.append(c)\n",
    "\n",
    "# Sort clusters based on the first row's last name (row[2])\n",
    "sorted_clusters = sorted(clusters, key=lambda cluster: cluster[0][2].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d335cd-18c3-4d07-9970-b2f9c2267bb2",
   "metadata": {},
   "source": [
    "## 4. Statistics and inconsistencies raising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f645db2-b4f9-4f31-981e-e260172906df",
   "metadata": {},
   "source": [
    "### Intra-cluster evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b25580-6f0c-423d-a95f-3b0faa436b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import Levenshtein\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def compute_statistics_by_prop(cluster, prop_value_ix):\n",
    "    \"\"\"Compute similarity statistics (mean, median, std) for embeddings cosine similarity and edit distance similarity.\"\"\"\n",
    "    \n",
    "    names = [row[prop_value_ix] for row in cluster]\n",
    "\n",
    "    if len(names) < 2:\n",
    "        return None  # No statistics if there's only one name\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = model.encode(names, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute pairwise similarities\n",
    "    embedding_similarities = []\n",
    "    edit_distances = []\n",
    "    \n",
    "    for name1, name2 in itertools.combinations(names, 2):\n",
    "        # Cosine similarity for embeddings\n",
    "        sim = util.pytorch_cos_sim(model.encode(name1, convert_to_tensor=True), \n",
    "                                   model.encode(name2, convert_to_tensor=True))\n",
    "        embedding_similarities.append(sim.item())\n",
    "\n",
    "        # Edit distance normalized (Levenshtein distance / max_length)\n",
    "        edit_distance = Levenshtein.distance(name1, name2) / max(len(name1), len(name2))\n",
    "        edit_distances.append(1 - edit_distance)  # Convert to similarity\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        \"Cosinus Similarity Mean (emb)\": np.mean(embedding_similarities),\n",
    "        \"Cosinus Similarity Median (emb)\": np.median(embedding_similarities),\n",
    "        \"Cosinus Similarity Std (emb)\": np.std(embedding_similarities),\n",
    "        \"Levenshtein Similarity Mean (str)\": np.mean(edit_distances),\n",
    "        \"Levenshtein Similarity Median (str)\": np.median(edit_distances),\n",
    "        \"Levenshtein Similarity Std (str)\": np.std(edit_distances),\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Process each cluster\n",
    "all_stats = []\n",
    "for i, cluster in enumerate(sorted_clusters):\n",
    "    stats_name = compute_statistics_by_prop(cluster,2)\n",
    "    stats_firstnames = compute_statistics_by_prop(cluster,3)\n",
    "    if stats:\n",
    "        stats[\"cluster_id\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bf42f0d-ba87-4639-bdf0-21e702e95130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 17 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9394\n",
      "  Cosinus Similarity Median (emb): 0.9092\n",
      "  Cosinus Similarity Std (emb): 0.0428\n",
      "  Levenshtein Similarity Mean (str): 0.9048\n",
      "  Levenshtein Similarity Median (str): 0.8571\n",
      "  Levenshtein Similarity Std (str): 0.0673\n",
      "  cluster_id: 17.0000\n",
      "[['21a8e30c-2ff8-44eb-a921-5fa3d4e95fea', 1, 'ancelet', 'nicolas jh'], ['8fab4098-b861-4399-a2c8-6f4a4f2bd4f0', 1, 'ancelot', 'nicolas jh'], ['69e3322e-1ed8-494e-a67c-efaad14a8da3', 1, 'ancelet', 'nicolas'], ['8a8e62da-6386-405d-bb13-8403563b61b7', 1, 'ancelot', 'nicolas joseph']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 21 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9092\n",
      "  Cosinus Similarity Median (emb): 0.9092\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.8571\n",
      "  Levenshtein Similarity Median (str): 0.8571\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 21.0000\n",
      "[['ec04a09f-1610-4d56-ac48-9e13c6db13d8', 1, 'ancelet', 'nicolas dit ancelon'], ['1a95c73d-2991-4aa1-97a1-0825275a8500', 1, 'ancelot', 'nicolas dit ancelon']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 26 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9394\n",
      "  Cosinus Similarity Median (emb): 0.9092\n",
      "  Cosinus Similarity Std (emb): 0.0428\n",
      "  Levenshtein Similarity Mean (str): 0.9048\n",
      "  Levenshtein Similarity Median (str): 0.8571\n",
      "  Levenshtein Similarity Std (str): 0.0673\n",
      "  cluster_id: 26.0000\n",
      "[['21a8e30c-2ff8-44eb-a921-5fa3d4e95fea', 1, 'ancelet', 'nicolas jh'], ['8fab4098-b861-4399-a2c8-6f4a4f2bd4f0', 1, 'ancelot', 'nicolas jh'], ['69e3322e-1ed8-494e-a67c-efaad14a8da3', 1, 'ancelet', 'nicolas']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 33 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9394\n",
      "  Cosinus Similarity Median (emb): 0.9092\n",
      "  Cosinus Similarity Std (emb): 0.0428\n",
      "  Levenshtein Similarity Mean (str): 0.9048\n",
      "  Levenshtein Similarity Median (str): 0.8571\n",
      "  Levenshtein Similarity Std (str): 0.0673\n",
      "  cluster_id: 33.0000\n",
      "[['21a8e30c-2ff8-44eb-a921-5fa3d4e95fea', 1, 'ancelet', 'nicolas jh'], ['8fab4098-b861-4399-a2c8-6f4a4f2bd4f0', 1, 'ancelot', 'nicolas jh'], ['8a8e62da-6386-405d-bb13-8403563b61b7', 1, 'ancelot', 'nicolas joseph']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 64 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8656\n",
      "  Cosinus Similarity Median (emb): 0.8656\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.8000\n",
      "  Levenshtein Similarity Median (str): 0.8000\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 64.0000\n",
      "[['50f1f353-3ec6-45af-a8f5-9a83da953fa7', 3, 'auvergne', ''], ['eec921ed-9269-4f28-add3-09582aacf54e', 4, 'd auvergne', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 252 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8915\n",
      "  Cosinus Similarity Median (emb): 0.8915\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.9091\n",
      "  Levenshtein Similarity Median (str): 0.9091\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 252.0000\n",
      "[['0ad656fa-c75d-49aa-b050-cb48ea9ec5b6', 1, 'bourdillat', 'jn'], ['fb7fc87a-acf6-4691-83bb-258d54ef54ce', 1, 'bourdilliat', 'jn guy']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 257 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8915\n",
      "  Cosinus Similarity Median (emb): 0.8915\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.9091\n",
      "  Levenshtein Similarity Median (str): 0.9091\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 257.0000\n",
      "[['4276d82c-8a66-4556-bf17-0805045887e7', 2, 'bourdilliat', 'pierre gilles'], ['0075e078-e13c-4be0-8f6d-9382087da197', 2, 'bourdillat', 'pierre gilles']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 327 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8509\n",
      "  Cosinus Similarity Median (emb): 0.8509\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.9091\n",
      "  Levenshtein Similarity Median (str): 0.9091\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 327.0000\n",
      "[['78134c67-8a09-4c44-a1a7-17cb59434d47', 1, 'chandennier', 'pre fois'], ['7160f940-7564-434b-91bf-f2559649ecd4', 1, 'chandennies', 'pre fois']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 395 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9132\n",
      "  Cosinus Similarity Median (emb): 0.8538\n",
      "  Cosinus Similarity Std (emb): 0.0768\n",
      "  Levenshtein Similarity Mean (str): 0.9485\n",
      "  Levenshtein Similarity Median (str): 0.9667\n",
      "  Levenshtein Similarity Std (str): 0.0637\n",
      "  cluster_id: 395.0000\n",
      "[['632e8609-a499-40ba-b760-6efbfb6aa1e2', 1, 'cie des chemins de fer de lest', ''], ['e43f21c3-1f2a-47b2-bde1-807db2e9809a', 1, 'cie des chmins de fer de lest', ''], ['7a6bc4d0-2814-44a8-9e5d-b1eb8e6243d0', 1, 'cie des chemins de fer de lest', ''], ['e24bc5b6-1eb9-48e1-a76e-f57d9d276ea4', 1, 'cie des chmins de fer de lest', ''], ['bb7d08fa-816b-431e-b4dc-2e7ee84db8c3', 1, 'cie chmins de fer de lest', ''], ['818af1e8-8bfa-4656-8989-e7e96d53292c', 1, 'cie des chemins de fer de lest', ''], ['44c187a5-9db6-4373-a6e8-daa1b84fb815', 1, 'cie des chemins de fer de lest', ''], ['e187fa75-5f32-4920-9dde-da110e2005a6', 1, 'cie des chemins de fer de lest', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 398 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9240\n",
      "  Cosinus Similarity Median (emb): 0.8860\n",
      "  Cosinus Similarity Std (emb): 0.0537\n",
      "  Levenshtein Similarity Mean (str): 0.8413\n",
      "  Levenshtein Similarity Median (str): 0.7619\n",
      "  Levenshtein Similarity Std (str): 0.1122\n",
      "  cluster_id: 398.0000\n",
      "[['1985ee91-700e-4370-9bc1-72e7871f9a4d', 1, 'cie du chemin de fer de paris a lyon', ''], ['70383869-5cfe-4cf5-9e95-53b49bc38568', 1, 'cie du chemin de fer de paris a lyon', ''], ['72909ba7-141d-45e0-b0ed-eae6edbee83e', 1, 'cie anonyme du chin de fer de paris a lyon', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 577 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8692\n",
      "  Cosinus Similarity Median (emb): 0.8692\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.7143\n",
      "  Levenshtein Similarity Median (str): 0.7143\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 577.0000\n",
      "[['3222815d-32d0-4655-a2c2-c87594478cc3', 1, 'delor', 'claude'], ['ce71f70e-c213-4745-af0f-066542bc9b28', 1, 'delorme', 'edouard']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 582 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9376\n",
      "  Cosinus Similarity Median (emb): 0.9064\n",
      "  Cosinus Similarity Std (emb): 0.0441\n",
      "  Levenshtein Similarity Mean (str): 0.9259\n",
      "  Levenshtein Similarity Median (str): 0.8889\n",
      "  Levenshtein Similarity Std (str): 0.0524\n",
      "  cluster_id: 582.0000\n",
      "[['494ef76b-7997-4ed5-a55a-a231f0db83fd', 1, 'demaisons', ''], ['75eee925-6a27-4833-b90f-c9dd5c270156', 1, 'demaison', ''], ['8aca74a5-3614-46e0-acf7-9d249624285c', 1, 'demaison', ''], ['692d6f47-0ad1-4d54-bbcc-0007cd8040b1', 1, 'demaisons', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 790 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8896\n",
      "  Cosinus Similarity Median (emb): 0.8896\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.9000\n",
      "  Levenshtein Similarity Median (str): 0.9000\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 790.0000\n",
      "[['48efedf2-2e9f-42a3-a273-a9192c63bfec', 1, 'gerande de', ''], ['1a0857ed-0165-4d90-b1db-ada45d95a9a0', 1, 'gerando de', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 809 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9073\n",
      "  Cosinus Similarity Median (emb): 0.9073\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.8750\n",
      "  Levenshtein Similarity Median (str): 0.8750\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 809.0000\n",
      "[['fdd5aafc-1765-4f19-aac0-57342fc478a0', 1, 'godetroy', ''], ['7630d229-5f55-4955-b8be-19757f8509b6', 1, 'godefroy', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 819 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9370\n",
      "  Cosinus Similarity Median (emb): 0.9370\n",
      "  Cosinus Similarity Std (emb): 0.0630\n",
      "  Levenshtein Similarity Mean (str): 0.9286\n",
      "  Levenshtein Similarity Median (str): 0.9286\n",
      "  Levenshtein Similarity Std (str): 0.0714\n",
      "  cluster_id: 819.0000\n",
      "[['eb007a65-3940-4532-88c5-0d5b7d56824c', 1, 'gratte', ''], ['a9422f07-c604-404f-bdd6-78d29b6aa811', 1, 'gratte', ''], ['1d209818-ff6a-43e5-b258-77ea60d9dd6c', 1, 'gratte', ''], ['5f2cb33d-b78a-4c61-98bf-41ae83f4777f', 1, 'grattey', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 938 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8935\n",
      "  Cosinus Similarity Median (emb): 0.8935\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.8000\n",
      "  Levenshtein Similarity Median (str): 0.8000\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 938.0000\n",
      "[['6f3d2caa-9e6f-4464-9be2-b1e880d09f0f', 1, 'hutin', ''], ['1dc1f7eb-2bfb-4b71-836f-e1a2e4da9011', 1, 'huten', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 1396 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9143\n",
      "  Cosinus Similarity Median (emb): 0.9143\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.9444\n",
      "  Levenshtein Similarity Median (str): 0.9444\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 1396.0000\n",
      "[['439dd50a-7c4b-4ac5-b2dc-2b8fabf7173a', 1, 'pelez de la lozere', ''], ['c5f7d51b-17ec-496f-8502-e5fa0069a845', 1, 'pelet de la lozere', '']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 1567 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.8558\n",
      "  Cosinus Similarity Median (emb): 0.8558\n",
      "  Cosinus Similarity Std (emb): 0.0000\n",
      "  Levenshtein Similarity Mean (str): 0.9000\n",
      "  Levenshtein Similarity Median (str): 0.9000\n",
      "  Levenshtein Similarity Std (str): 0.0000\n",
      "  cluster_id: 1567.0000\n",
      "[['5da4f480-89ac-43b7-979a-7383d726aaf8', 1, 'reuzeville', 'charles alexis'], ['23e82dcf-f094-4283-929f-cf59c33f86a6', 1, 'beuzeville', 'charles alexis']]\n",
      "\n",
      "---\n",
      "\n",
      "Cluster 1617 Statistics:\n",
      "  Cosinus Similarity Mean (emb): 0.9245\n",
      "  Cosinus Similarity Median (emb): 0.8741\n",
      "  Cosinus Similarity Std (emb): 0.0617\n",
      "  Levenshtein Similarity Mean (str): 0.9250\n",
      "  Levenshtein Similarity Median (str): 0.8750\n",
      "  Levenshtein Similarity Std (str): 0.0612\n",
      "  cluster_id: 1617.0000\n",
      "[['101062dc-ceef-4ba4-912a-bd3fa8b5253c', 1, 'saussary', ''], ['b6d74d66-0cde-4f6b-85dc-5cc61dc7b032', 1, 'saussay', ''], ['9562302c-9362-4beb-a75b-0dc5b639c73c', 1, 'saussay', ''], ['ed98c804-8bbc-4113-ba03-a70a2ac0d448', 1, 'saussary', ''], ['b369a174-07f6-495e-8558-24725fbc00a8', 1, 'saussay', '']]\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for stats in all_stats:\n",
    "    if stats[\"Cosinus Similarity Mean (emb)\"] < 0.95 and stats[\"Levenshtein Similarity Mean (str)\"] < 0.95:\n",
    "        print(f\"Cluster {stats['cluster_id']} Statistics:\")\n",
    "        for key, value in stats.items():\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        print(sorted_clusters[stats['cluster_id']])\n",
    "        print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a413b6-7ec7-4f13-b95f-da3d5052b006",
   "metadata": {},
   "source": [
    "### Inter-cluster evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73efada8-d5b7-4bdc-b2bb-60d6eb0074a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Store visualization data\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "all_clusters = []\n",
    "representative_points = []\n",
    "\n",
    "for i, cluster in enumerate(sorted_clusters):\n",
    "    # Extract names\n",
    "    names = [row[2] + ' ' + row[3] for row in cluster]\n",
    "\n",
    "        # Compute embeddings\n",
    "    embeddings = model.encode(names)\n",
    "\n",
    "    if len(cluster) == 1:\n",
    "        # If only one element, keep it as is\n",
    "        all_embeddings.append(embeddings[0])\n",
    "        all_labels.append(names[0])\n",
    "        all_clusters.append(i)\n",
    "    else:\n",
    "        # Compute centroid of cluster\n",
    "        centroid = np.mean(embeddings, axis=0)\n",
    "\n",
    "        # Find closest element to centroid\n",
    "        distances = [np.linalg.norm(embedding - centroid) for embedding in embeddings]\n",
    "        most_representative_idx = np.argmin(distances)\n",
    "\n",
    "        all_embeddings.append(embeddings[most_representative_idx])\n",
    "        all_labels.append(names[most_representative_idx])\n",
    "        all_clusters.append(i)\n",
    "\n",
    "# Reduce dimensions using PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2D = pca.fit_transform(all_embeddings)\n",
    "\n",
    "# Create scatter plot\n",
    "fig = px.scatter(\n",
    "    x=embeddings_2D[:, 0], y=embeddings_2D[:, 1], \n",
    "    hover_name=all_labels,  # Show labels only on hover\n",
    "    color=[str(c) for c in all_clusters],  # Cluster coloring\n",
    "    title=\"Clustered Names in 2D Space (via PCA)\",\n",
    "    labels={\"x\": \"PCA Component 1\", \"y\": \"PCA Component 2\"},\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.write_html(\"clusters.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b4782-fc6c-4eb0-ab77-41272bbe8e4a",
   "metadata": {},
   "source": [
    "## 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6aa688aa-e908-476e-897a-15bf48b6a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "\n",
    "# Convert tensors to CPU and numpy\n",
    "data2 = [[row[0], row[1].cpu().numpy(), row[2].cpu().numpy()] for row in name_sim[:500]]\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for row in data2:\n",
    "    x_val = row[0]  # First number in each list\n",
    "    y_vals = row[2]  # Second list (numbers for y-axis)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[x_val] * len(y_vals), y=y_vals, mode='markers', name=f'Group {x_val}'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title=\"Plotly Scatter Plot\",\n",
    "                  xaxis_title=\"Group Number\",\n",
    "                  yaxis_title=\"Values\",\n",
    "                  showlegend=True)\n",
    "\n",
    "# Show figure\n",
    "fig.write_html(\"scatter_plot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b32a8a6-44cb-4a11-bd53-984d4a22a1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file 'box_plot.html' has been created.\n"
     ]
    }
   ],
   "source": [
    "# Convert tensors to CPU and numpy\n",
    "data2 = [[row[0], row[1].cpu().numpy(), row[2].cpu().numpy()] for row in name_sim[:500]]\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "for row in data2:\n",
    "    x_val = row[0]  # First number in each list (Group)\n",
    "    y_vals = row[2]  # Second list (numbers for y-axis)\n",
    "\n",
    "    fig.add_trace(go.Box(y=y_vals, name=f'Group {x_val}', boxpoints=\"outliers\", boxmean=True))  # Box plot for each group\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title=\"Box Plot of Values per Group\",\n",
    "                  xaxis_title=\"Group Number\",\n",
    "                  yaxis_title=\"Values\",\n",
    "                  showlegend=True)\n",
    "\n",
    "# Save figure as HTML\n",
    "fig.write_html(\"box_plot2.html\")\n",
    "\n",
    "print(\"HTML file 'box_plot.html' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f8e836b-e45a-4255-b8d0-ccaad4467af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file 'box_plot_deciles_outliers.html' has been created.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert tensors to CPU and numpy\n",
    "data2 = [[row[0], row[1].cpu().numpy(), row[2].cpu().numpy()] for row in name_sim[:500]]\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "for row in data2:\n",
    "    x_val = row[0]  # First number in each list (Group)\n",
    "    y_vals = row[2]  # Second list (numbers for y-axis)\n",
    "\n",
    "    # Compute deciles (10th, 20th, ..., 90th percentiles)\n",
    "    percentiles = np.percentile(y_vals, [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "\n",
    "    # Outlier values (values greater than 90th percentile)\n",
    "    outliers = y_vals[y_vals > percentiles[8]]\n",
    "\n",
    "    # Create box plot with custom percentiles (deciles)\n",
    "    fig.add_trace(go.Box(\n",
    "        y=y_vals,\n",
    "        x=[x_val] * len(y_vals),  # Use x-values for positioning each box plot vertically\n",
    "        name=f'Group {x_val}',\n",
    "        boxmean=True,  # Show mean\n",
    "        whiskerwidth=1,  # Make whiskers thicker\n",
    "        boxpoints='all',  # Show all points, including outliers\n",
    "        jitter=0.3,  # Add jitter to show outliers clearly\n",
    "        #whiskerlength=0.5,  # Whisker length for clarity\n",
    "        lowerfence=[percentiles[0]],  # 10th percentile as a list\n",
    "        upperfence=[percentiles[8]],  # 90th percentile (D9) as a list\n",
    "        q1=[percentiles[1]],  # 20th percentile\n",
    "        median=[percentiles[4]],  # 50th percentile (median)\n",
    "        q3=[percentiles[7]],  # 80th percentile\n",
    "        #outliercolor='red',  # Set the outlier color\n",
    "    ))\n",
    "\n",
    "    # Plot outliers manually above D9\n",
    "    for outlier in outliers:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[x_val],\n",
    "            y=[outlier],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red', size=10, symbol='circle'),\n",
    "            name=f'Outlier Group {x_val}',\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "# Update layout for vertical orientation\n",
    "fig.update_layout(\n",
    "    title=\"Box Plot with Deciles and Outliers\",\n",
    "    xaxis_title=\"Group Number\",\n",
    "    yaxis_title=\"Values\",\n",
    "    showlegend=True,\n",
    "    boxmode='group',  # Group the boxes by x values\n",
    "    height=600  # Adjust the height for better visualization\n",
    ")\n",
    "\n",
    "# Save figure as HTML\n",
    "fig.write_html(\"box_plot_deciles_outliers.html\")\n",
    "\n",
    "print(\"HTML file 'box_plot_deciles_outliers.html' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "468a8ba8-ce4c-49c4-bdc3-aacdec4b706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file 'marginal_plot_y_values.html' has been created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# Convert tensors to CPU and numpy for plotting\n",
    "data2 = [[row[0], row[2].cpu().numpy()] for row in name_sim[:500]]\n",
    "\n",
    "# Flatten data for a single DataFrame\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "\n",
    "for row in data2:\n",
    "    x_vals.extend([row[0]] * len(row[1]))  # Repeat the group number (row[0]) for each y value\n",
    "    y_vals.extend(row[1])  # Add all the y values (row[2])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Group': x_vals,\n",
    "    'Value': y_vals\n",
    "})\n",
    "\n",
    "# Create a marginal plot\n",
    "fig = px.scatter(df, x='Group', y='Value', marginal_y='histogram', \n",
    "                 title=\"Scatter Plot with Marginal Histogram on Y values\",\n",
    "                 labels={'Group': 'Group Number', 'Value': 'Y Values'})\n",
    "\n",
    "# Save figure as HTML\n",
    "fig.write_html(\"marginal_plot_y_values500.html\")\n",
    "\n",
    "print(\"HTML file 'marginal_plot_y_values.html' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bfc7ac95-1981-498d-a9a3-e75f4892fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file 'marginal_plot_with_deciles_and_centiles.html' has been created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# Convert tensors to CPU and numpy for plotting\n",
    "data2 = [[row[0], row[2].cpu().numpy()] for row in name_sim[:500]]\n",
    "\n",
    "# Flatten data for a single DataFrame\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "\n",
    "for row in data2:\n",
    "    x_vals.extend([row[0]] * len(row[1]))  # Repeat the group number (row[0]) for each y value\n",
    "    y_vals.extend(row[1])  # Add all the y values (row[2])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Group': x_vals,\n",
    "    'Value': y_vals\n",
    "})\n",
    "\n",
    "# Compute deciles (10th, 20th, ..., 90th percentiles)\n",
    "deciles = np.percentile(y_vals, np.arange(10, 100, 10))\n",
    "\n",
    "# Compute centiles (91st, 92nd, ..., 100th percentiles)\n",
    "centiles = np.percentile(y_vals, np.arange(91, 101, 1))\n",
    "\n",
    "# Create a marginal plot with scatter and histogram\n",
    "fig = px.scatter(df, x='Group', y='Value', marginal_y='histogram', \n",
    "                 title=\"Scatter Plot with Marginal Histogram on Y values\",\n",
    "                 labels={'Group': 'Group Number', 'Value': 'Y Values'})\n",
    "\n",
    "# Add decile lines to scatter plot\n",
    "for decile in deciles:\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=df['Group'].min(), x1=df['Group'].max(),\n",
    "        y0=decile, y1=decile,\n",
    "        line=dict(color=\"blue\", dash=\"dash\", width=2),\n",
    "    )\n",
    "\n",
    "# Add centile lines to scatter plot\n",
    "for centile in centiles:\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=df['Group'].min(), x1=df['Group'].max(),\n",
    "        y0=centile, y1=centile,\n",
    "        line=dict(color=\"green\", dash=\"dashdot\", width=2),\n",
    "    )\n",
    "\n",
    "# Add decile lines to marginal histogram (horizontal lines)\n",
    "for decile in deciles:\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=0, x1=1,\n",
    "        y0=decile, y1=decile,\n",
    "        yref=\"y2\",  # Reference to the marginal y-axis\n",
    "        line=dict(color=\"blue\", dash=\"dash\", width=2),\n",
    "    )\n",
    "\n",
    "# Add centile lines to marginal histogram (horizontal lines)\n",
    "for centile in centiles:\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=0, x1=1,\n",
    "        y0=centile, y1=centile,\n",
    "        yref=\"y2\",  # Reference to the marginal y-axis\n",
    "        line=dict(color=\"green\", dash=\"dashdot\", width=2),\n",
    "    )\n",
    "\n",
    "# Save figure as HTML\n",
    "fig.write_html(\"marginal_plot_with_deciles_and_centiles.html\")\n",
    "\n",
    "print(\"HTML file 'marginal_plot_with_deciles_and_centiles.html' has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
