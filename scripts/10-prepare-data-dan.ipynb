{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset for DAN training\n",
    "\n",
    "Pour Assia : tu n'as pas besoin d'exécuter cette partie du code, c'est pour te montrer comment est produit le fichier ```split.json``` à adapter à tes données.\n",
    "\n",
    "PS : Tu n'as pas besoin des fichiers language_model et charset.pkl pour la tâche de détection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset entities\n",
    "\n",
    "Pour Assia : étape à passer\n",
    "\n",
    "Extract list of entities.</br>\n",
    "In : SQLite database</br>\n",
    "Out : entities.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!teklia-dan dataset entities /workspaces/DAN-cadastre/epita-ign-registre-napoleonien-20240308-170022.sqlite --output-file /workspaces/DAN-cadastre/dataset/entities.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset tokens\n",
    "\n",
    "Pour Assia : étape à passer\n",
    "\n",
    "Generate a YAML file containing entities and their tokens to train et DAN model.</br>\n",
    "In : entries.yaml</br>\n",
    "Out : tokens.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!teklia-dan dataset tokens /workspaces/DAN-cadastre/dataset/entities.yml \\\n",
    "    --output-file /workspaces/DAN-cadastre/dataset/tokens.yml \\\n",
    "    --end-tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset extraction\n",
    "Pour Assia : à passer, je t'envoie le fichier split.json pour que tu puisses en créer un à partir de tes données \n",
    "\n",
    "**Commande utilisée pour produire le fichier *split.json*.** \n",
    "Il contient trois clés de niveau 1 : train, val et test. Puis chaque élément dans chacune de ces clés correspond à une boite annotée sur une image de carte.\n",
    "```\n",
    "{\n",
    "        \"017ddb7f-6a6d-4ecd-a0f5-71f13f99e8d4\": {\n",
    "            \"dataset_id\": \"032ae384-77dd-4ec8-868a-4348dd74897f\",\n",
    "            \"image\": {\n",
    "                \"iiif_url\": \"https://iiif.geohistoricaldata.org/iiif/2/CADASTRE%2FETATS_DE_SECTION%2F%2FBOISSY%2FFRAD094_3P_000065_01%2FFRAD094_3P_000065_01_0058.jpg\",\n",
    "                \"polygon\": [\n",
    "                    [\n",
    "                        304,\n",
    "                        2998\n",
    "                    ],\n",
    "                    [\n",
    "                        304,\n",
    "                        3198\n",
    "                    ],\n",
    "                    [\n",
    "                        2933,\n",
    "                        3198\n",
    "                    ],\n",
    "                    [\n",
    "                        2933,\n",
    "                        2998\n",
    "                    ],\n",
    "                    [\n",
    "                        304,\n",
    "                        2998\n",
    "                    ]\n",
    "                ]\n",
    "            },\n",
    "            \"text\": \"\\u24c291\\u24c3 \\u24baidem\\u24bb \\u24c011\\u24c1 \\u24bebois\\u24bf\"\n",
    "        },\n",
    "```\n",
    "avec : \n",
    "- ```\"017ddb7f-6a6d-4ecd-a0f5-71f13f99e8d4\":``` : exemple d'identifiant d'un polygone annoté (tu peux créer des identifiants pour tes polygones d'annotations. Par exemple : ```nom-image_word-id```)\n",
    "- ```\"dataset_id\": \"032ae384-77dd-4ec8-868a-4348dd74897f\"``` : identifiant du dataset dans la platforme d'annotation, tu peux laisser cette valeure\n",
    "- ```iiif_url```: chemin de l'image qui contient ton polygone\n",
    "- ```polygon``` : coordonnées du polygone dans l'image\n",
    "- ```text``` : transcription du mot\n",
    "\n",
    "Extract annotations from the SQLITE database to JSON.</br>\n",
    "In : SQLite database</br>\n",
    "Out : JSON text annotation dataset : split.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from page (c6cee0c1-eef6-4b9b-b5c4-5a823518066b) for split (trai2024-06-26 12:28:55,412 WARNING/dan.datasets.extract.arkindex: Skipping e29d8be0-1c42-4548-a168-16b20c4c37c1: No transcriptions found on element (e29d8be0-1c42-4548-a168-16b20c4c37c1) with this config. Skipping.\n",
      "Extracting data from page (114c87cf-f591-415f-8687-1d518399572a) for split (trai2024-06-26 12:28:57,016 WARNING/dan.datasets.extract.arkindex: Skipping c6e64c03-c526-45e8-8348-af4100287e91: No transcriptions found on element (c6e64c03-c526-45e8-8348-af4100287e91) with this config. Skipping.\n",
      "Extracting data from page (114c87cf-f591-415f-8687-1d518399572a) for split (trai2024-06-26 12:28:57,054 WARNING/dan.datasets.extract.arkindex: Skipping db49735a-6476-452f-a4f3-6a000762ba2f: No transcriptions found on element (db49735a-6476-452f-a4f3-6a000762ba2f) with this config. Skipping.\n",
      "Extracting data from page (114c87cf-f591-415f-8687-1d518399572a) for split (trai2024-06-26 12:28:57,054 WARNING/dan.datasets.extract.arkindex: Skipping 24733d32-e339-46e9-b451-157d3c475fcd: No transcriptions found on element (24733d32-e339-46e9-b451-157d3c475fcd) with this config. Skipping.\n",
      "Extracting data from page (c29fcfaa-ed19-40e3-8324-8843ae89b2cd) for split (trai2024-06-26 12:28:59,270 WARNING/dan.datasets.extract.arkindex: Skipping 91649f27-3b1c-4631-8620-ea10a9c89b26: No transcriptions found on element (91649f27-3b1c-4631-8620-ea10a9c89b26) with this config. Skipping.\n",
      "Extracting data from page (c29fcfaa-ed19-40e3-8324-8843ae89b2cd) for split (trai2024-06-26 12:28:59,322 WARNING/dan.datasets.extract.arkindex: Skipping 769f4307-dbe9-41f2-9b01-66e0c27889ca: No transcriptions found on element (769f4307-dbe9-41f2-9b01-66e0c27889ca) with this config. Skipping.\n",
      "Extracting data from page (6903e4c0-f037-4105-86a2-85ba867a8895) for split (trai                                      \n",
      "Extracting data from page (43534ab4-6452-4c18-8ffe-d135cfcfc99f) for split (test                                    \n",
      "Extracting data from page (b639929c-28e0-4533-b374-36173c224f6b) for split (val)                                   \n",
      "2024-06-26 12:29:04,254 INFO/dan.datasets.extract.arkindex: Preparing language resources\n",
      "2024-06-26 12:29:04,256 INFO/dan.datasets.extract.utils: Training a sentencepiece model for subword tokenization\n"
     ]
    }
   ],
   "source": [
    "!teklia-dan dataset extract /workspaces/DAN-cadastre/epita-ign-registre-napoleonien-20240308-170022.sqlite \\\n",
    "    --dataset-id 032ae384-77dd-4ec8-868a-4348dd74897f \\\n",
    "    --element-type tab_line \\\n",
    "    --output /workspaces/DAN-cadastre/dataset/tab_line_dataset \\\n",
    "    --tokens /workspaces/DAN-cadastre/dataset/tokens.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download IIIF images\n",
    "\n",
    "Pour Assia : étape à passer, tu as déjà tes images en local => mettre les chemins des emplacements des images dans la clé \"iiif_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images:  28%|█████▋              | 752/2642 [03:14<10:32,  2.99it/s]2024-03-06 16:08:50,678 WARNING/dan.datasets.download.utils: Request to https://iiif.geohistoricaldata.org/iiif/2/CADASTRE%2FETATS_DE_SECTION%2F%2FSAINTMANDE%2F3P_000514%2FFRAD094_3P_000514_0084.jpg/447,2579,2533,162/full/0/default.jpg failed (ProxyError(MaxRetryError(\"HTTPSConnectionPool(host='iiif.geohistoricaldata.org', port=443): Max retries exceeded with url: /iiif/2/CADASTRE%2FETATS_DE_SECTION%2F%2FSAINTMANDE%2F3P_000514%2FFRAD094_3P_000514_0084.jpg/447,2579,2533,162/full/0/default.jpg (Caused by ProxyError('Cannot connect to proxy.', TimeoutError('_ssl.c:980: The handshake operation timed out')))\"))), retrying in 2.0 seconds\n",
      "Downloading images: 100%|███████████████████| 2642/2642 [11:11<00:00,  3.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#!teklia-dan dataset download --output /home/STual/dataset/tab_line_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
